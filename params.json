{"name":"Moodytube","tagline":"ITSP 2015 Project.","body":"# MoodyTube\r\n**A Django powered website that plays music according to your mood**\r\n##Music Player:\r\nWe have used last.fm's API that allows to access their database with songs sorted by tags. Then these songs are searched on YouTube using their Data API and the first result is considered.\r\n##Mood Detection:\r\nThere are 3 parts to this process:\r\n###1. Pre-Processing:\r\n**The images from training dataset are first rotated such that eyes are horizontally aligned.**<br>\r\nFor this, first eyes are detected using eye haarcascade and the eyeballs are detected by Shi-Tomasi corner detection method.\r\n![Eye detection](/Screenshots/eye_detect.png)<br>\r\n![Aligned Image](/Screenshots/align.png)<br><br>\r\n**The aligned image is then resized so that distance between the eyes is equal to that of the sample image.**<br>\r\nSample image considered in this case:<br>\r\n![Sample image](/Screenshots/sample.bmp)<br><br>\r\n**The training set images are then cropped so that eyes each of the training set image coincides with eyes of the sample image**<br>\r\nFor this, coordinates of the midpoint of the eyes is calculated relative to the border of the sample image. The image is cropped along the border calculated according to midpoint of the eyes of sample image.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}