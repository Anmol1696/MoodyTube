<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Moodytube by adityapb</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Moodytube</h1>
      <h2 class="project-tagline">ITSP 2015 Project.</h2>
      <a href="https://github.com/adityapb/MoodyTube" class="btn">View on GitHub</a>
      <a href="https://github.com/adityapb/MoodyTube/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/adityapb/MoodyTube/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="moodytube" class="anchor" href="#moodytube" aria-hidden="true"><span class="octicon octicon-link"></span></a>MoodyTube</h1>

<p><strong>A Django powered website that plays music according to your mood</strong></p>

<h2>
<a id="music-player" class="anchor" href="#music-player" aria-hidden="true"><span class="octicon octicon-link"></span></a>Music Player:</h2>

<p>We have used last.fm's API that allows to access their database with songs sorted by tags. Then these songs are searched on YouTube using their Data API and the first result is considered.</p>

<h2>
<a id="mood-detection" class="anchor" href="#mood-detection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mood Detection:</h2>

<p>There are 3 parts to this process:</p>

<h3>
<a id="1-pre-processing" class="anchor" href="#1-pre-processing" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Pre-Processing:</h3>

<p><strong>The images from training dataset are first rotated such that eyes are horizontally aligned.</strong><br>
For this, first eyes are detected using eye haarcascade and the eyeballs are detected by Shi-Tomasi corner detection method.
<img src="https://raw.githubusercontent.com/adityapb/MoodyTube/gh-pages/Screenshots/eye_detect.png" alt="Eye detection"><br>
<img src="https://raw.githubusercontent.com/adityapb/MoodyTube/gh-pages/Screenshots/align.png" alt="Aligned Image"><br><br>
<strong>The aligned image is then resized so that distance between the eyes is equal to that of the sample image.</strong><br>
Sample image considered in this case:<br>
<img src="https://raw.githubusercontent.com/adityapb/MoodyTube/gh-pages/Screenshots/sample.bmp" alt="Sample image"><br><br>
<strong>The training set images are then cropped so that eyes each of the training set image coincides with eyes of the sample image</strong><br>
For this, coordinates of the midpoint of the eyes is calculated relative to the border of the sample image. The image is cropped along the border calculated according to midpoint of the eyes of sample image.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/adityapb/MoodyTube">Moodytube</a> is maintained by <a href="https://github.com/adityapb">adityapb</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>

